{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('../data/kc_house_train_data.csv', delimiter=',', skip_header=1)\n",
    "d_test = np.genfromtxt('../data/kc_house_test_data.csv', delimiter=',', skip_header=1)\n",
    "# since we imported them with numpy, the first row with chars \n",
    "# might be nan's, so we want to effectively ignore that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_feat(feature, degree):\n",
    "    assert(isinstance(degree, int))\n",
    "    assert(degree > 0)\n",
    "    final_ft = np.empty((feature.shape[0], degree))\n",
    "    final_ft[:, 0] = feature\n",
    "    for i in range(2, degree + 1):\n",
    "        final_ft[:, i - 1] = np.power(feature, i)\n",
    "    return final_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = data[:, 5]\n",
    "output = data[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.argsort(inp)\n",
    "# sort the input and output according to the appropriate indices. \n",
    "inp_sorted = inp[idx]\n",
    "output_sorted = output[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degree = 15\n",
    "cc = polynomial_feat(inp_sorted, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape input and output to use sklearn\n",
    "if degree == 1:\n",
    "    cc = cc.reshape((cc.shape[0], 1))\n",
    "\n",
    "# perform ridge regression\n",
    "l2_small_penalty = 1.5e-5\n",
    "regr1 = linear_model.Ridge(alpha=l2_small_penalty, normalize=True)\n",
    "regr1.fit(cc, output_sorted)\n",
    "# predict the values\n",
    "yp1 = regr1.predict(cc)\n",
    "# print the coefficients\n",
    "print('Coefficients for regression of degree {} are {}'.format(degree, regr1.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and fit on different subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = np.genfromtxt('../data/wk3_kc_house_set_1_data.csv', delimiter=',', skip_header=1)\n",
    "d2 = np.genfromtxt('../data/wk3_kc_house_set_2_data.csv', delimiter=',', skip_header=1)\n",
    "d3 = np.genfromtxt('../data/wk3_kc_house_set_3_data.csv', delimiter=',', skip_header=1)\n",
    "d4 = np.genfromtxt('../data/wk3_kc_house_set_4_data.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aux_prepare_data(d, l2_penalty, degree=15, inp=5, out=2, verbose=True):\n",
    "    # auxiliary function that: a) forms the input/output vectors, b) creates a linear \n",
    "    # prediction for the data provided. \n",
    "    inp = d[:, inp]\n",
    "    output = d[:, out]\n",
    "    idx = np.argsort(inp)\n",
    "    # sort the input and output according to the appropriate indices. \n",
    "    inp_sorted = inp[idx]\n",
    "    output_sorted = output[idx]\n",
    "    cc = polynomial_feat(inp_sorted, degree)\n",
    "    \n",
    "    # perform linear regression\n",
    "    # reshape input and output to use sklearn\n",
    "    if degree == 1:\n",
    "        cc = cc.reshape((cc.shape[0], 1))\n",
    "    \n",
    "    # build linear regression model\n",
    "    regr1 = linear_model.Ridge(alpha=l2_penalty, normalize=True)\n",
    "    regr1.fit(cc, output_sorted)\n",
    "    # predict the values\n",
    "    yp = regr1.predict(cc)\n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        print(regr1.intercept_, regr1.coef_)\n",
    "        plt.plot(cc, output_sorted, '.', cc, yp, '-')\n",
    "    \n",
    "    return cc, yp, output_sorted, regr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2_small_penalty=1e-9\n",
    "cc1, yp1, out1, regr1 = aux_prepare_data(d1, l2_small_penalty)\n",
    "cc2, yp2, out2, regr2 = aux_prepare_data(d2, l2_small_penalty)\n",
    "cc3, yp3, out3, regr3 = aux_prepare_data(d3, l2_small_penalty)\n",
    "cc4, yp4, out4, regr4 = aux_prepare_data(d4, l2_small_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit with a large penalty\n",
    "l2_large_penalty=1.23e2\n",
    "cc1, yp1, out1, regr1 = aux_prepare_data(d1, l2_large_penalty)\n",
    "cc2, yp2, out2, regr2 = aux_prepare_data(d2, l2_large_penalty)\n",
    "cc3, yp3, out3, regr3 = aux_prepare_data(d3, l2_large_penalty)\n",
    "cc4, yp4, out4, regr4 = aux_prepare_data(d4, l2_large_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation for selecting L2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_rss_ridge(y_pred, y_true, w):\n",
    "    erri = y_pred - y_true\n",
    "    return np.sum(np.multiply(erri, erri)) + np.linalg.norm(w, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_valid(d, d_valid, l2_penalty, degree=1):\n",
    "    inp = d[1:, 5]\n",
    "    output = d[1:, 2]\n",
    "    cc = polynomial_feat(inp, degree)\n",
    "    assert(cc.shape[1] == degree)\n",
    "    \n",
    "    # perform ridge regression\n",
    "    # reshape input and output to use sklearn\n",
    "    if degree == 1:\n",
    "        cc = cc.reshape((cc.shape[0], 1))\n",
    "    \n",
    "    # build linear regression model\n",
    "    regr1 = linear_model.Ridge(alpha=l2_penalty, normalize=True)\n",
    "    regr1.fit(cc, output)\n",
    "    \n",
    "    # predict the values (validation set)\n",
    "    inp_v = d_valid[:, 5]\n",
    "    output_v = d_valid[:, 2]\n",
    "    \n",
    "    inp_v = polynomial_feat(inp_v, degree)\n",
    "    assert(inp_v.shape[1] == degree)\n",
    "    if degree == 1:\n",
    "        inp_v = inp_v.reshape((inp_v.shape[0], 1))\n",
    "    yp = regr1.predict(inp_v)\n",
    "    \n",
    "    return compute_rss_ridge(yp, output_v, regr1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_fold_exec(k, n, train_valid_shuffled, l2_penalty):\n",
    "    sum_rss = 0\n",
    "    for i in xrange(k):\n",
    "        start = (n*i)/k\n",
    "        end = (n*(i+1))/k-1\n",
    "    #     print i, (start, end)\n",
    "        val = train_valid_shuffled[start:end+1, :]  # validation set\n",
    "        # create a new temp array for the training and then assign the training data\n",
    "        tr = np.empty((n - (end-start) - 1, train_valid_shuffled.shape[1]))\n",
    "        tr[0:start, :] = train_valid_shuffled[0:start, :]\n",
    "        tr[start:, :] = train_valid_shuffled[end + 1:, :]\n",
    "        assert(tr.shape[1] == val.shape[1] and \n",
    "               tr.shape[0] + val.shape[0] == train_valid_shuffled.shape[0])\n",
    "        # call the function that performs the feature extraction and the ridge regression\n",
    "        rss = train_valid(tr, val, l2_penalty, degree=15)\n",
    "        sum_rss += rss\n",
    "    sum_rss /= k\n",
    "    return sum_rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_valid_shuffled = np.genfromtxt('../data/wk3_kc_house_train_valid_shuffled.csv', \n",
    "                                     delimiter=',', skip_header=1)\n",
    "n = len(train_valid_shuffled)\n",
    "k = 10  # 10-fold cross-validation\n",
    "l2_best = -1\n",
    "cost = 10 ** 18\n",
    "\n",
    "for cnt, l2_penalty in enumerate(np.logspace(3, 9, num=13)):\n",
    "    c1 = one_fold_exec(k, n, train_valid_shuffled, l2_penalty)\n",
    "    print('penalty: {}, cost: {}'.format(np.round(l2_penalty), c1))\n",
    "    if c1 < cost:\n",
    "        cost = c1\n",
    "        l2_best = l2_penalty\n",
    "assert(l2_best > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_valid(train_valid_shuffled, d_test, l2_best, degree=15) / 10 ** 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
